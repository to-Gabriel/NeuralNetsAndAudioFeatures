{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6e8748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 18:28:39.336147: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a3fad",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca6a6ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (3014, 200, 200, 3)\n",
      "Validation set: (1710, 200, 200, 3)\n",
      "Test set: (13306, 200, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "dataset= '/home/madan005/dev/deeplearning/MFCC'\n",
    "\n",
    "train_dataset      = os.path.join(dataset, 'train')\n",
    "validation_dataset = os.path.join(dataset, 'dev')\n",
    "test_dataset       = os.path.join(dataset, 'eval')\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder, label, target_size=(200, 200)):\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(folder):\n",
    "        filepath = os.path.join(folder, filename)\n",
    "        image = Image.open(filepath)\n",
    "        image = image.convert('RGB')\n",
    "        image = image.resize(target_size, Image.LANCZOS)\n",
    "        images.append(np.array(image))\n",
    "        labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Initialize lists for train, validation, and test sets\n",
    "X_train, y_train = [], []\n",
    "X_val,   y_val   = [], []\n",
    "X_test,  y_test  = [], []\n",
    "\n",
    "# training data\n",
    "for class_name in ['genuine', 'spoof']:\n",
    "    class_folder = os.path.join(train_dataset, class_name)\n",
    "    label = 1 if class_name == 'genuine' else 0\n",
    "    imgs, labels = load_images_from_folder(class_folder, label)\n",
    "    X_train.extend(imgs)\n",
    "    y_train.extend(labels)\n",
    "    \n",
    "# validation data\n",
    "for class_name in ['genuine', 'spoof']:\n",
    "    class_folder = os.path.join(validation_dataset, class_name)\n",
    "    label = 1 if class_name == 'genuine' else 0\n",
    "    imgs, labels = load_images_from_folder(class_folder, label)\n",
    "    X_val.extend(imgs)\n",
    "    y_val.extend(labels)\n",
    "\n",
    "# test data\n",
    "for class_name in ['genuine', 'spoof']:\n",
    "    class_folder = os.path.join(test_dataset, class_name)\n",
    "    label = 1 if class_name == 'genuine' else 0\n",
    "    imgs, labels = load_images_from_folder(class_folder, label)\n",
    "    X_test.extend(imgs)\n",
    "    y_test.extend(labels)\n",
    "\n",
    "\n",
    "\n",
    "# numpy arrays\n",
    "X_train = np.array(X_train, dtype='float32') / 255.0\n",
    "y_train = np.array(y_train)\n",
    "X_val   = np.array(X_val,   dtype='float32') / 255.0\n",
    "y_val   = np.array(y_val)\n",
    "X_test  = np.array(X_test,  dtype='float32') / 255.0\n",
    "y_test  = np.array(y_test)\n",
    "\n",
    "# shapes\n",
    "print(\"Training set:\", X_train.shape)\n",
    "print(\"Validation set:\", X_val.shape)\n",
    "print(\"Test set:\", X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9378723b",
   "metadata": {},
   "source": [
    "class distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cf650ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training:\n",
      "  spoof: 1507\n",
      "  genuine: 1507\n",
      "\n",
      "Validation:\n",
      "  spoof: 950\n",
      "  genuine: 760\n",
      "\n",
      "Test:\n",
      "  spoof: 12008\n",
      "  genuine: 1298\n"
     ]
    }
   ],
   "source": [
    "# class counts \n",
    "for split_name, labels in [\n",
    "    ('Training', y_train),\n",
    "    ('Validation', y_val),\n",
    "    ('Test', y_test)\n",
    "]:\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    for cls, cnt in zip(unique, counts):\n",
    "        name = 'genuine' if cls == 1 else 'spoof'\n",
    "        print(f\"  {name}: {cnt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be1e8b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 18:29:28.183663: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6386880000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)) \\\n",
    "    .shuffle(buffer_size=1000) \\\n",
    "    .batch(BATCH_SIZE) \\\n",
    "    .prefetch(AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)) \\\n",
    "    .batch(BATCH_SIZE) \\\n",
    "    .prefetch(AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test)) \\\n",
    "    .batch(BATCH_SIZE) \\\n",
    "    .prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101bc20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madan005/miniconda3/envs/my_env/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16928</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,333,824</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │         \u001b[38;5;34m3,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m97\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m73,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m18,464\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16928\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m4,333,824\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,430,817</span> (16.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,430,817\u001b[0m (16.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,430,369</span> (16.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,430,369\u001b[0m (16.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backend.clear_session()\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "img_height, img_width = 200, 200\n",
    "input_shape = (img_height, img_width, 3)\n",
    "\n",
    "# model\n",
    "model = Sequential([\n",
    "  Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=input_shape), \n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  BatchNormalization(),\n",
    "  \n",
    "  Conv2D(64, (3, 3), activation='relu',  kernel_regularizer=regularizers.l2(0.001)), \n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  BatchNormalization(),\n",
    "  \n",
    "  Conv2D(32, (3, 3), activation='relu',  kernel_regularizer=regularizers.l2(0.001)), \n",
    "  MaxPooling2D(pool_size=(2, 2)),\n",
    "  BatchNormalization(),\n",
    "  \n",
    "  Flatten(),\n",
    "  Dense(256, activation=\"relu\"),\n",
    "  Dropout(0.2),\n",
    "  Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cec6649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.8815 - auc: 0.0000e+00 - loss: 0.3757 - val_accuracy: 0.4450 - val_auc: 0.5045 - val_loss: 0.8291\n",
      "Epoch 2/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.1328 - val_accuracy: 0.4444 - val_auc: 0.4850 - val_loss: 0.8472\n",
      "Epoch 3/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - accuracy: 0.9004 - auc: 0.4990 - loss: 2.6162 - val_accuracy: 0.4444 - val_auc: 0.5289 - val_loss: 0.8608\n",
      "Epoch 4/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.6254 - auc: 0.6130 - loss: 0.9274 - val_accuracy: 0.4444 - val_auc: 0.5370 - val_loss: 0.8622\n",
      "Epoch 5/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.6520 - auc: 0.6908 - loss: 0.7795 - val_accuracy: 0.4444 - val_auc: 0.5453 - val_loss: 0.8765\n",
      "Epoch 6/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.6326 - auc: 0.6857 - loss: 0.7588 - val_accuracy: 0.4444 - val_auc: 0.5498 - val_loss: 0.8875\n",
      "Epoch 7/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - accuracy: 0.6853 - auc: 0.6845 - loss: 0.7193 - val_accuracy: 0.4444 - val_auc: 0.5500 - val_loss: 0.9166\n",
      "Epoch 8/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8269 - auc: 0.8619 - loss: 0.5171 - val_accuracy: 0.4444 - val_auc: 0.5585 - val_loss: 0.9472\n",
      "Epoch 9/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8148 - auc: 0.7951 - loss: 0.5582 - val_accuracy: 0.4444 - val_auc: 0.5656 - val_loss: 0.9795\n",
      "Epoch 10/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8140 - auc: 0.8436 - loss: 0.5538 - val_accuracy: 0.4444 - val_auc: 0.5515 - val_loss: 1.0131\n",
      "Epoch 11/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8435 - auc: 0.9204 - loss: 0.4632 - val_accuracy: 0.4444 - val_auc: 0.5528 - val_loss: 1.0446\n",
      "Epoch 12/30\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 763ms/step - accuracy: 0.9180 - auc: 0.8897 - loss: 0.4147"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 18:32:34.618236: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/home/madan005/miniconda3/envs/my_env/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9131 - auc: 0.8880 - loss: 0.4174 - val_accuracy: 0.4444 - val_auc: 0.5558 - val_loss: 1.0648\n",
      "Epoch 13/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6467 - auc: 0.0000e+00 - loss: 0.7721 - val_accuracy: 0.4444 - val_auc: 0.5541 - val_loss: 1.1352\n",
      "Epoch 14/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.1533 - val_accuracy: 0.4444 - val_auc: 0.5541 - val_loss: 1.2001\n",
      "Epoch 15/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.9245 - auc: 0.7194 - loss: 0.5191 - val_accuracy: 0.4444 - val_auc: 0.5574 - val_loss: 1.1905\n",
      "Epoch 16/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1s/step - accuracy: 0.7250 - auc: 0.7039 - loss: 1.0238 - val_accuracy: 0.4444 - val_auc: 0.5636 - val_loss: 1.1024\n",
      "Epoch 17/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6783 - auc: 0.7544 - loss: 0.7258 - val_accuracy: 0.4444 - val_auc: 0.5743 - val_loss: 1.0793\n",
      "Epoch 18/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7438 - auc: 0.7876 - loss: 0.6951 - val_accuracy: 0.4444 - val_auc: 0.5858 - val_loss: 1.0998\n",
      "Epoch 19/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7403 - auc: 0.7835 - loss: 0.6267 - val_accuracy: 0.4444 - val_auc: 0.5836 - val_loss: 1.1785\n",
      "Epoch 20/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8191 - auc: 0.8591 - loss: 0.5419 - val_accuracy: 0.4444 - val_auc: 0.5867 - val_loss: 1.2498\n",
      "Epoch 21/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8305 - auc: 0.8671 - loss: 0.4945 - val_accuracy: 0.4444 - val_auc: 0.5926 - val_loss: 1.3088\n",
      "Epoch 22/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8769 - auc: 0.9028 - loss: 0.4525 - val_accuracy: 0.4444 - val_auc: 0.5894 - val_loss: 1.2828\n",
      "Epoch 23/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.9010 - auc: 0.9344 - loss: 0.3673 - val_accuracy: 0.4444 - val_auc: 0.5950 - val_loss: 1.2727\n",
      "Epoch 24/30\n",
      "\u001b[1m7/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 781ms/step - accuracy: 0.8886 - auc: 0.9476 - loss: 0.3937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 18:34:47.902965: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8855 - auc: 0.9449 - loss: 0.3981 - val_accuracy: 0.4444 - val_auc: 0.6145 - val_loss: 1.2083\n",
      "Epoch 25/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8605 - auc: 0.0000e+00 - loss: 0.4023 - val_accuracy: 0.4444 - val_auc: 0.6121 - val_loss: 1.2060\n",
      "Epoch 26/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.1222 - val_accuracy: 0.4444 - val_auc: 0.6100 - val_loss: 1.2217\n",
      "Epoch 27/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.9227 - auc: 0.6488 - loss: 0.5849 - val_accuracy: 0.4444 - val_auc: 0.6107 - val_loss: 1.1715\n",
      "Epoch 28/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7937 - auc: 0.8972 - loss: 0.5505 - val_accuracy: 0.4444 - val_auc: 0.5922 - val_loss: 1.1526\n",
      "Epoch 29/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7849 - auc: 0.9008 - loss: 0.5904 - val_accuracy: 0.4444 - val_auc: 0.5835 - val_loss: 1.2094\n",
      "Epoch 30/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8578 - auc: 0.9264 - loss: 0.4817 - val_accuracy: 0.4444 - val_auc: 0.5863 - val_loss: 1.2541\n"
     ]
    }
   ],
   "source": [
    "# Updated training call using the tf.data datasets\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    steps_per_epoch=8,\n",
    "    epochs=30,\n",
    "    validation_data=val_ds\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cc2540d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step\n",
      "\u001b[1m  1/416\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m46s\u001b[0m 111ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 18:36:13.261544: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 6386880000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m416/416\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 76ms/step\n",
      "\n",
      "=== Classification Report — Train ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       spoof       0.00      0.00      0.00      1507\n",
      "     genuine       0.50      1.00      0.67      1507\n",
      "\n",
      "    accuracy                           0.50      3014\n",
      "   macro avg       0.25      0.50      0.33      3014\n",
      "weighted avg       0.25      0.50      0.33      3014\n",
      "\n",
      "\n",
      "=== Classification Report — Validation ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       spoof       0.00      0.00      0.00       950\n",
      "     genuine       0.44      1.00      0.62       760\n",
      "\n",
      "    accuracy                           0.44      1710\n",
      "   macro avg       0.22      0.50      0.31      1710\n",
      "weighted avg       0.20      0.44      0.27      1710\n",
      "\n",
      "\n",
      "=== Classification Report — Test ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       spoof       0.00      0.00      0.00     12008\n",
      "     genuine       0.10      1.00      0.18      1298\n",
      "\n",
      "    accuracy                           0.10     13306\n",
      "   macro avg       0.05      0.50      0.09     13306\n",
      "weighted avg       0.01      0.10      0.02     13306\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madan005/miniconda3/envs/my_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/madan005/miniconda3/envs/my_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/madan005/miniconda3/envs/my_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/madan005/miniconda3/envs/my_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/madan005/miniconda3/envs/my_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/madan005/miniconda3/envs/my_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/madan005/miniconda3/envs/my_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/madan005/miniconda3/envs/my_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/madan005/miniconda3/envs/my_env/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred_train_raw = model.predict(X_train)\n",
    "y_pred_val_raw   = model.predict(X_val)\n",
    "y_pred_test_raw  = model.predict(X_test)\n",
    "\n",
    "#discrete labels\n",
    "def to_labels(probs):\n",
    "    # multi-class?\n",
    "    if probs.ndim > 1 and probs.shape[1] > 1:\n",
    "        return probs.argmax(axis=1)\n",
    "    # binary-probabilities => threshold at 0.5\n",
    "    return (probs > 0.5).astype(int).ravel()\n",
    "\n",
    "y_pred_train = to_labels(y_pred_train_raw)\n",
    "y_pred_val   = to_labels(y_pred_val_raw)\n",
    "y_pred_test  = to_labels(y_pred_test_raw)\n",
    "\n",
    "#   class names\n",
    "target_names = ['spoof', 'genuine']\n",
    "\n",
    "#Loop through each split\n",
    "for split_name, y_true, y_pred in [\n",
    "    ('Train',      y_train, y_pred_train),\n",
    "    ('Validation', y_val,   y_pred_val),\n",
    "    ('Test',       y_test,  y_pred_test)\n",
    "]:\n",
    "    print(f\"\\n=== Classification Report — {split_name} ===\")\n",
    "    print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "    \n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
